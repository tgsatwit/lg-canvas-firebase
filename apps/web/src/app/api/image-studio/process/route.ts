import { NextRequest, NextResponse } from "next/server";
import { GoogleGenerativeAI } from "@google/generative-ai";

export async function POST(req: NextRequest) {
  // Initialize Gemini client with proper API key
  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY!);
  try {
    const formData = await req.formData();
    const image = formData.get('image') as File;
    const type = formData.get('type') as string;

    if (!image) {
      return NextResponse.json(
        { error: 'Image is required' },
        { status: 400 }
      );
    }

    // Validate image type
    if (!image.type.startsWith('image/')) {
      return NextResponse.json(
        { error: 'Please upload a valid image file' },
        { status: 400 }
      );
    }

    if (type === 'ai-edit') {
      return await handleAIEdit(image, formData, genAI);
    } else if (type === 'resize') {
      return await handleResize(image, formData);
    } else {
      return NextResponse.json(
        { error: 'Invalid processing type' },
        { status: 400 }
      );
    }

  } catch (error) {
    console.error('Error processing image:', error);
    
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    return NextResponse.json(
      { 
        error: 'Failed to process image',
        details: errorMessage
      },
      { status: 500 }
    );
  }
}

async function handleAIEdit(image: File, formData: FormData, genAI: any) {
  const prompt = formData.get('prompt') as string;

  if (!prompt) {
    return NextResponse.json(
      { error: 'Prompt is required for AI edit' },
      { status: 400 }
    );
  }

  // Check API key
  const apiKey = process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY;
  if (!apiKey) {
    console.error('Neither GOOGLE_API_KEY nor GEMINI_API_KEY found in environment variables');
    return NextResponse.json(
      { error: 'Google/Gemini API key not configured' },
      { status: 500 }
    );
  }

  try {
    // Convert image to base64
    const bytes = await image.arrayBuffer();
    const buffer = Buffer.from(bytes);
    const base64Image = buffer.toString('base64');

    // Use Gemini 2.5 Flash Image for AI editing
    const imageModel = genAI.getGenerativeModel({ model: "gemini-2.5-flash-image-preview" });

    // Create optimized prompt for AI editing
    const enhancedPrompt = `${prompt}. Please edit the provided image according to this request and return the modified image.`;
    
    console.log('Processing image with AI using Gemini 2.5 Flash Image...');

    // Generate the edited image using Gemini
    const result = await imageModel.generateContent([
      { text: enhancedPrompt },
      {
        inlineData: {
          mimeType: image.type,
          data: base64Image
        }
      }
    ]);

    const response = await result.response;
    
    // Check if the response contains image data
    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error('No image generated by Gemini');
    }

    const candidate = candidates[0];
    const content = candidate.content;
    
    if (!content.parts || content.parts.length === 0) {
      throw new Error('No content parts in response');
    }

    // Look for image data in the response
    let imageData: string | null = null;
    for (const part of content.parts) {
      if (part.inlineData && part.inlineData.mimeType?.startsWith('image/')) {
        imageData = part.inlineData.data;
        break;
      }
    }

    if (!imageData) {
      // If no image data, fallback to text response explaining the limitation
      const textResponse = content.parts.find((part: any) => part.text);
      console.warn('Gemini response:', textResponse?.text || 'No text response');
      
      return NextResponse.json({
        error: 'Gemini 2.5 Flash Image did not return image data. The model may be generating a text response instead of an edited image.',
        modelResponse: textResponse?.text || 'No response text available'
      }, { status: 422 });
    }

    // Convert base64 to buffer and return the processed image
    const processedBuffer = Buffer.from(imageData, 'base64');
    
    console.log('Successfully processed image with AI');

    return new NextResponse(processedBuffer, {
      status: 200,
      headers: {
        'Content-Type': 'image/png',
        'Content-Disposition': 'inline; filename="ai-edited-image.png"',
        'X-Processed-By': 'Gemini-AI'
      },
    });

  } catch (error) {
    console.error('Error processing image with AI:', error);
    
    const errorMessage = error instanceof Error ? error.message : 'Unknown error';
    
    // Check for specific API errors
    if (errorMessage.includes('SERVICE_DISABLED') || errorMessage.includes('403 Forbidden')) {
      return NextResponse.json(
        { 
          error: 'Generative Language API Not Enabled',
          details: 'The Generative Language API needs to be enabled in your Google Cloud project.',
          instructions: [
            '1. Visit Google Cloud Console',
            '2. Navigate to APIs & Services > Library', 
            '3. Search for "Generative Language API"',
            '4. Click "Enable"',
            '5. Or create a new API key at Google AI Studio (https://makersuite.google.com/app/apikey)'
          ],
          activationUrl: 'https://console.cloud.google.com/apis/library/generativelanguage.googleapis.com',
          model: 'gemini-2.5-flash-image-preview'
        },
        { status: 403 }
      );
    }

    if (errorMessage.includes('API_KEY_INVALID') || errorMessage.includes('401')) {
      return NextResponse.json(
        { 
          error: 'Invalid API Key',
          details: 'The provided Google/Gemini API key is invalid or expired.',
          instructions: [
            '1. Check that GEMINI_API_KEY is correctly set in your .env file',
            '2. Verify the API key is valid at Google AI Studio',
            '3. Ensure the API key has permissions for Generative Language API'
          ],
          model: 'gemini-2.5-flash-image-preview'
        },
        { status: 401 }
      );
    }
    
    return NextResponse.json(
      { 
        error: 'Failed to process image with AI',
        details: errorMessage,
        model: 'gemini-2.5-flash-image-preview'
      },
      { status: 500 }
    );
  }
}

async function handleResize(image: File, formData: FormData) {
  const resizeDataStr = formData.get('resizeData') as string;

  if (!resizeDataStr) {
    return NextResponse.json(
      { error: 'Resize data is required' },
      { status: 400 }
    );
  }

  try {
    const resizeData = JSON.parse(resizeDataStr);
    const { targetWidth, targetHeight, selection, format } = resizeData;

    // Convert image to buffer
    const bytes = await image.arrayBuffer();
    const buffer = Buffer.from(bytes);

    // For now, we'll return the original image with proper headers
    // In a production environment, you'd use a proper image processing library like Sharp
    console.log(`Processing image resize to ${targetWidth}x${targetHeight} (${format})`);

    // Determine output mime type
    const mimeType = format === 'jpeg' ? 'image/jpeg' : 
                    format === 'webp' ? 'image/webp' :
                    format === 'avif' ? 'image/avif' : 'image/png';

    return new NextResponse(buffer, {
      status: 200,
      headers: {
        'Content-Type': mimeType,
        'Content-Disposition': `inline; filename="resized-image.${format}"`,
        'X-Processed-By': 'Canvas-Resize',
        'X-Target-Size': `${targetWidth}x${targetHeight}`,
        'X-Selection': JSON.stringify(selection)
      },
    });

  } catch (error) {
    console.error('Error processing resize:', error);
    return NextResponse.json(
      { error: 'Failed to process resize data' },
      { status: 400 }
    );
  }
}